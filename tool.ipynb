{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import all the packages/libraries first! <font color=\"#FF0000\">(Execute Only)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run scripts/tfidf_cfidf_process_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modin Pandas (parallel version of Pandas) <font color=\"#FF0000\">(Execute Only)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import modin pandas for tackling with large dataset\n",
    "import modin.pandas as mpd\n",
    "from modin.config import ProgressBar\n",
    "ProgressBar.enable()\n",
    "\n",
    "# Use dask as modin engine\n",
    "import modin.config as cfg\n",
    "cfg.Engine.put(\"dask\")\n",
    "\n",
    "## ================\n",
    "## If you don't know what it is doing\n",
    "## Don't touch!\n",
    "## ================\n",
    "from dask.distributed import Client\n",
    "## ================\n",
    "## If you have 8 cores & Working string/dictionaries data\n",
    "## n_workers = 4\n",
    "## threads_per_worker= 2\n",
    "## ==OR==\n",
    "## If you have 8 cores & Working numeric data\n",
    "## n_workers = 2\n",
    "## threads_per_worker= 4\n",
    "## !!! The parameters are depend on what you are going to do !!!\n",
    "## ================\n",
    "client = Client(processes=True, n_workers=4, threads_per_worker=4)\n",
    "swifter.register_modin()  # start distributed scheduler locally\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Convert xlsx format to csv format (optional) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 831/831 [00:13<00:00, 62.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Convert xlsx format to csv format\n",
    "# client.restart()\n",
    "from datetime import datetime\n",
    "column = \"\"\n",
    "error_list = []\n",
    "now = datetime.now()\n",
    "error_filename = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "def loadDataset_xlsx(btn):\n",
    "  global CSV_PATH\n",
    "  CSV_PATH = glob.glob(path.join(folder_pathDisplay1.value, file_dropdown1.value, '*.xlsx'))\n",
    "  print(f\"Successfully set {CSV_PATH[0]} and the rest as dataset source\")\n",
    " \n",
    "def xlsxToCSV(btn):\n",
    "  clear_output(wait=True)\n",
    "  print('Processing!')\n",
    "  for XLSX in tqdm(CSV_PATH, desc=\"Progress: \", ncols=100):\n",
    "    dest_filename = path.basename(XLSX).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    try:\n",
    "        skipRow = 1 if checkbox_skipFirstRow.value else 0\n",
    "        if checkbox_header.value:\n",
    "          df = pd.read_excel(XLSX, skiprows=skipRow)\n",
    "          df.to_csv(destination, encoding=\"utf-8-sig\", index=False)\n",
    "        else:\n",
    "          df = pd.read_excel(XLSX, header=None, skiprows=skipRow)\n",
    "          df.to_csv(destination, encoding=\"utf-8-sig\", index=False, header=None)\n",
    "    except:\n",
    "        error_list.append(XLSX)\n",
    "        print(\"Error occurred\")\n",
    "  if len(error_list) > 0:\n",
    "    print(\"Error list is saved to root folder\")\n",
    "    with open(\"Section3.1_\" + error_filename + \".txt\", \"w\") as file:\n",
    "      file.write(\"\\r\\n\".join(error_list))\n",
    "  print('Done')\n",
    " \n",
    "# Configure & Reload Widgets\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_setDest = button('Select Column!')\n",
    "btn_exeFx = button('Execute!')\n",
    "checkbox_header = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Contain header?',\n",
    "    disabled=False\n",
    ")\n",
    "checkbox_skipFirstRow = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Skip first row?',\n",
    "    disabled=False\n",
    ")\n",
    " \n",
    "btn_load1.on_click(loadDataset_xlsx)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_exeFx.on_click(xlsxToCSV)\n",
    " \n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  checkbox_header,\n",
    "  checkbox_skipFirstRow,\n",
    "  btn_load1\n",
    "])\n",
    " \n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    " \n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    " \n",
    "tab.children = [tab_load1, tab_setDest, tab_execute]\n",
    "for index, title in enumerate([tabTitles2[0],tabTitles2[5],tabTitles2[-1]]):\n",
    "  tab.set_title(index, title)\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Add column name (optional) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.1 Add column name\n",
    "columns = []\n",
    "tabColumns = Tab()\n",
    "\n",
    "def loadColumns(btn):\n",
    "  global columns, tabColumns\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    children = [widgets.Text(name=x) for x in columns]\n",
    "    tabColumns.children = children\n",
    "    for i, column in enumerate(columns):\n",
    "      tabColumns.set_title(i, column)\n",
    "      # tabColumns.children[i].value = column\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def setColumnsName(btn):\n",
    "  global columns\n",
    "  columns = [text.value for text in tabColumns.children]\n",
    "  print(f\"Column name: {columns}\")\n",
    "\n",
    "def addColumnName(btn):\n",
    "  print('Processing')\n",
    "  for CSV in tqdm(CSV_PATH, desc=\"Progress: \", ncols=100):\n",
    "    lines = \"\"\n",
    "    with open(CSV, 'r', encoding='utf-8-sig') as file:\n",
    "      lines = file.readlines()\n",
    "    lines.insert(0, \",\".join(columns) + \"\\n\")\n",
    "    # lines[0] = \",\".join(columns) + \"\\n\"\n",
    "    with open(CSV, 'w', encoding='utf-8-sig') as file:\n",
    "      file.writelines(lines)\n",
    "  print('Done')\n",
    "  \n",
    "# Configure & Reload Widgets\n",
    "input_Text = inputText('File name:')\n",
    "\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_load2 = button('Load First File!')\n",
    "btn_setColumnName = button('Set!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_load2.on_click(loadColumns)\n",
    "btn_setColumnName.on_click(setColumnsName)\n",
    "btn_exeFx.on_click(addColumnName)\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "tab_setColumnName = VBox([\n",
    "  widgets.HTML(value=\"<b>Set the name of the columns!!</b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>If you want to use our tool</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Make sure to set the text data column name to 'content'</font></b>\"),\n",
    "  btn_load2,\n",
    "  tabColumns,\n",
    "  btn_setColumnName\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab.children = [tab_load1, tab_setColumnName, tab_execute]\n",
    "for index, title in enumerate([tabTitles2[0],tabTitles2[1], tabTitles2[-1]]):\n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Rename columns (optional) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.2 Rename columns\n",
    "columns = []\n",
    "tabColumns = Tab()\n",
    "\n",
    "def loadColumns(btn):\n",
    "  global columns, tabColumns\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    children = [widgets.Text(name=x) for x in columns]\n",
    "    tabColumns.children = children\n",
    "    for i, column in enumerate(columns):\n",
    "      tabColumns.set_title(i, column)\n",
    "      tabColumns.children[i].value = column\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def setColumnsName(btn):\n",
    "  global columns\n",
    "  columns = [text.value for text in tabColumns.children]\n",
    "  print(f\"Column name: {columns}\")\n",
    "\n",
    "def replaceColumnName(btn):\n",
    "  clear_output(wait=True)\n",
    "  print('Processing')\n",
    "  for CSV in tqdm(CSV_PATH, desc=\"Progress: \", ncols=100):\n",
    "    lines = \"\"\n",
    "    with open(CSV, 'r', encoding='utf-8-sig') as file:\n",
    "      lines = file.readlines()\n",
    "    lines[0] = \",\".join(columns) + \"\\n\"\n",
    "    with open(CSV, 'w', encoding='utf-8-sig') as file:\n",
    "      file.writelines(lines)\n",
    "  print('Done')\n",
    "  \n",
    "# Configure & Reload Widgets\n",
    "input_Text = inputText('File name:')\n",
    "\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_load2 = button('Load First File!')\n",
    "btn_setColumnName = button('Set!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_load2.on_click(loadColumns)\n",
    "btn_setColumnName.on_click(setColumnsName)\n",
    "btn_exeFx.on_click(replaceColumnName)\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "tab_reNameColumns = VBox([\n",
    "  widgets.HTML(value=\"<b>Set the name of the columns!!</b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>If you want to use our tool</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Make sure to set the text data column name to 'content'</font></b>\"),\n",
    "  btn_load2,\n",
    "  tabColumns,\n",
    "  btn_setColumnName\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab.children = [tab_load1, tab_reNameColumns, tab_execute]\n",
    "for index, title in enumerate([tabTitles2[0],tabTitles2[1], tabTitles2[-1]]):\n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Drop columns (optional) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.3 Drop columns\n",
    "client.restart() #Restart Dask\n",
    "RANGE = 1\n",
    "columnsToDrop = []\n",
    "\n",
    "def loadColumns_1(btn):\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_1.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def addColumnsToDrop(btn):\n",
    "  global columnsToDrop\n",
    "  columnsToDrop.append(columnsDropdown_1.value)\n",
    "  print(f\"Columns to be Ignored: {columnsToDrop}\")\n",
    "\n",
    "def resetColumns(btn):\n",
    "  global columnsToDrop\n",
    "  columnsToDrop.clear()\n",
    "  print(f\"Columns to be Ignored: {columnsToDrop}\")\n",
    "\n",
    "def dropColumns(btn):\n",
    "  clear_output(wait=True)\n",
    "  for CSV in tqdm(list(CSV_PATH)[RANGE-1:], desc = f\"Progress\", ncols=100):\n",
    "  # for CSV in track(list(CSV_PATH)[RANGE-1:], description=f\"Conversion Progress\"):\n",
    "    # Initislization\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df = df.drop(columnsToDrop, axis=1)\n",
    "    df.to_csv(destination, encoding='utf-8-sig', index=False)\n",
    "\n",
    "# =======================================================\n",
    "# =======================================================\n",
    "# =======================================================\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "# columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_loadColumns_1 = button('Load Columns!')\n",
    "btn_addColumn_output = button('Add to drop list!')\n",
    "btn_resetColumn_output = button('Reset!')\n",
    "btn_setDest = button('Set Path')\n",
    "btn_setRange = button('Set Range!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_loadColumns_1.on_click(loadColumns_1)\n",
    "btn_addColumn_output.on_click(addColumnsToDrop)\n",
    "btn_resetColumn_output.on_click(resetColumns)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(dropColumns)\n",
    "\n",
    "input_boundedInt = boundedInt()\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "tab_setDropColumns = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will set the output format of your work</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Drop unwanted columns: </font></b>\"),\n",
    "  btn_loadColumns_1,\n",
    "  columnsDropdown_1,\n",
    "  HBox([\n",
    "  btn_addColumn_output,\n",
    "  btn_resetColumn_output\n",
    "  ])\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "#Tab\n",
    "tab.children = [tab_load1, tab_setDropColumns, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([tabTitles2[0], \"Drop Columns\"] \\\n",
    "  + tabTitles[3:]):\n",
    "  \n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Split dataset in CSV format according to column (optional) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Split dataset according to column\n",
    "# client.restart()\n",
    "column = \"\"\n",
    "fileName = \"\"\n",
    "\n",
    "def loadColumns_1(btn):\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def selectColumn(btn):\n",
    "  global column\n",
    "  column = columnsDropdown.value\n",
    "  print(f\"Split dataset according to {column}\")\n",
    "\n",
    "def mergeToSingleCSV():\n",
    "  print('Processing')\n",
    "  global fileName\n",
    "  fileName = path.join(folder_pathDisplay1.value, \"temp_merged.csv\")\n",
    "  with open(fileName, 'w', encoding='utf-8-sig') as file:\n",
    "    for p_index, CSV in tqdm(list(enumerate(CSV_PATH)), desc=\"Progress: \", ncols=100):\n",
    "      with open(CSV, encoding=\"utf-8-sig\") as f:\n",
    "          for idx, line in enumerate(f):\n",
    "              if p_index == 0 and idx == 0:\n",
    "                file.write(line)\n",
    "              elif idx>0:\n",
    "                file.write(line)\n",
    "  print('Done')\n",
    "  \n",
    "def splitCSV(btn):\n",
    "  clear_output(wait=True)\n",
    "  print('Processing!')\n",
    "  if len(CSV_PATH) > 1:\n",
    "    mergeToSingleCSV()\n",
    "    df = mpd.read_csv(fileName, encoding='utf-8-sig').groupby(column)\n",
    "  else:\n",
    "    df = mpd.read_csv(CSV_PATH[0], encoding='utf-8-sig').groupby(column)\n",
    "  # df_date = df.groupby('date')\n",
    "  # DEST_PATH = path.join(DIR, 'data_full_csv_date')\n",
    "  for name, dataframe in tqdm(np.array(df), desc = f\"Conversion Progress\", ncols=100):\n",
    "    dest_filename = str(name) + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    try:\n",
    "        dataframe.to_csv(destination, encoding=\"utf-8-sig\", index=False)\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "  print('Done')\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_loadColumns_1= button('Load Columns!')\n",
    "btn_selectColumn = button('Select Column!')\n",
    "btn_setDest = button('Select Column!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_loadColumns_1.on_click(loadColumns_1)\n",
    "btn_selectColumn.on_click(selectColumn)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_exeFx.on_click(splitCSV)\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will process One/Multiple CSV files, put the file(s) into a folder</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>**Multiple files: This also create a temp_merged.csv file to the root folder, you may either make good use of it or delete it</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "tab_selectSplitColumn = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Split dataset according to which column? :</font></b>\"),\n",
    "  btn_loadColumns_1,\n",
    "  columnsDropdown,\n",
    "  btn_selectColumn\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab.children = [tab_load1, tab_selectSplitColumn, tab_setDest, tab_execute]\n",
    "for index, title in enumerate([tabTitles2[0],tabTitles2[2],tabTitles2[5],tabTitles2[-1]]):\n",
    "  tab.set_title(index, title)\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Data cleaning (optional) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Data cleaning\n",
    "#Data Cleaning function (Single)\n",
    "#==========ReEx pattern==========\n",
    "# URL_PATTERN = r'(?<=[^.])((?:(?:https?|ftp|file)://|(?<![a-zA-Z\\-\\.])www\\.)' \\\n",
    "#               r'[\\-A-Za-z0-9\\+&@\\(\\)#/%\\?=\\~_|!:\\,\\.\\;]+[\\-A-Za-z0-9\\+&@#/%=\\~_\\|])' \\\n",
    "#               r'(?=[<\\u4E00-\\u9FA5Ôø•Ôºå„ÄÇÔºõÔºÅÔºü„ÄÅ‚Äú‚Äù‚Äò‚Äô>ÔºàÔºâ‚Äî„Ää„Äã‚Ä¶‚óè \\t\\n])'\n",
    "URL_PATTERN = r'((?:(?:https?|ftp|file)://|(?<![a-zA-Z\\-\\.])www\\.)' \\\n",
    "              r'[\\-A-Za-z0-9\\+&@\\(\\)#/%\\?=\\~_|!:\\,\\.\\;]+[\\-A-Za-z0-9\\+&@#/%=\\~_\\|])' \\\n",
    "              r'(?=[<\\u4E00-\\u9FA5Ôø•Ôºå„ÄÇÔºõÔºÅÔºü„ÄÅ‚Äú‚Äù‚Äò‚Äô>ÔºàÔºâ‚Äî„Ää„Äã‚Ä¶‚óè \\t\\n])'\n",
    "# HTML Tag Clearing     \n",
    "re_HTML = re.compile('<.*?>')\n",
    "# Custom Characters\n",
    "re_Characters = re.compile('[=&,.%;Ôºö:()ÔºàÔºâ„Äê„ÄëÔºªÔºΩ„Äé„Äè„Äå„Äç„ÄÇ„ÄÅÔºå!ÔºÅ?Ôºü\"\\[\\]\\-\\s+]+')\n",
    "re_Characters2 = re.compile('[‚ùåüò≠‚úÇÔ∏èüëêüèª+]+')\n",
    "re_Characters_All = re.compile('[\\W ]+')\n",
    "# Chinese & English Space Clearing\n",
    "re_ChiEng_Space = re.compile('([\\u4e00-\\u9fff])\\s+([\\u4e00-\\u9fff])')\n",
    "re_ChiEng_Space2 = re.compile('([a-zA-Z])\\s+([\\u4e00-\\u9fff])')\n",
    "re_ChiEng_Space3 = re.compile('([\\u4e00-\\u9fff])\\s+([a-zA-Z])')\n",
    "# Numbers & Chinses Clearing\n",
    "re_Number_Space = re.compile('([\\u4e00-\\u9fff])\\s+([0-9])')\n",
    "re_Number_Space2 = re.compile('([0-9])\\s+([\\u4e00-\\u9fff])')\n",
    "re_Number_Space3 = re.compile('([0-9])\\s+([0-9])')\n",
    "# URL Clearing\n",
    "re_URL_PATTERN = re.compile(URL_PATTERN)\n",
    "re_URL_PATTERN2 = re.compile(r'[a-zA-Z]+://[\\S]+\\.[net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil|be|hk][\\S]*\\s?[\\u4e00-\\u9fff]?')\n",
    "re_EmptyCell = r'^\\s*$'\n",
    "#FULL_WIDTH to HALF_WIDTH\n",
    "WIDTH_MAP = {'„ÄÄ': ' ', 'ÔºÅ': '!', 'ÔºÇ': '\"', 'ÔºÉ': '#', 'ÔºÑ': '$', 'ÔºÖ': '%', 'ÔºÜ': '&', \n",
    "       'Ôºá': \"'\", 'Ôºà': '(', 'Ôºâ': ')', 'Ôºä': '*', 'Ôºã': '+', 'Ôºå': ',', 'Ôºç': '-', \n",
    "       'Ôºé': '.', 'Ôºè': '/', \n",
    "       'Ôºê': '0', 'Ôºë': '1', 'Ôºí': '2', 'Ôºì': '3', 'Ôºî': '4', 'Ôºï': '5', 'Ôºñ': '6', \n",
    "       'Ôºó': '7', 'Ôºò': '8', 'Ôºô': '9', \n",
    "       'Ôºö': ':', 'Ôºõ': ';', 'Ôºú': '<', 'Ôºù': '=', 'Ôºû': '>', 'Ôºü': '?', 'Ôº†': '@',\n",
    "       'Ôº°': 'A', 'Ôº¢': 'B', 'Ôº£': 'C', 'Ôº§': 'D', 'Ôº•': 'E', 'Ôº¶': 'F', 'Ôºß': 'G',\n",
    "       'Ôº®': 'H', 'Ôº©': 'I', 'Ôº™': 'J', 'Ôº´': 'K', 'Ôº¨': 'L', 'Ôº≠': 'M', 'ÔºÆ': 'N',\n",
    "       'ÔºØ': 'O', 'Ôº∞': 'P', 'Ôº±': 'Q', 'Ôº≤': 'R', 'Ôº≥': 'S', 'Ôº¥': 'T', 'Ôºµ': 'U',\n",
    "       'Ôº∂': 'V', 'Ôº∑': 'W', 'Ôº∏': 'X', 'Ôºπ': 'Y', 'Ôº∫': 'Z', \n",
    "       'Ôºª': '[', 'Ôºº': '\\\\', \n",
    "       'ÔºΩ': ']', 'Ôºæ': '^', 'Ôºø': '_', 'ÔΩÄ': '`',\n",
    "       'ÔΩÅ': 'a', 'ÔΩÇ': 'b', 'ÔΩÉ': 'c', 'ÔΩÑ': 'd', 'ÔΩÖ': 'e', 'ÔΩÜ': 'f', 'ÔΩá': 'g',\n",
    "       'ÔΩà': 'h', 'ÔΩâ': 'i', 'ÔΩä': 'j', 'ÔΩã': 'k', 'ÔΩå': 'l', 'ÔΩç': 'm', 'ÔΩé': 'n',\n",
    "       'ÔΩè': 'o', 'ÔΩê': 'p', 'ÔΩë': 'q', 'ÔΩí': 'r', 'ÔΩì': 's', 'ÔΩî': 't', 'ÔΩï': 'u',\n",
    "       'ÔΩñ': 'v', 'ÔΩó': 'w', 'ÔΩò': 'x', 'ÔΩô': 'y', 'ÔΩö': 'z', \n",
    "       'ÔΩõ': '{', 'ÔΩú': '|', 'ÔΩù': '}'}\n",
    "\n",
    "re_FullWidth = re.compile(r'[\\u3000ÔºÅÔºÇÔºÉÔºÑÔºÖÔºÜÔºáÔºàÔºâÔºäÔºãÔºåÔºçÔºéÔºèÔºêÔºëÔºíÔºìÔºîÔºïÔºñÔºóÔºòÔºô'\\\n",
    "            r'ÔºöÔºõÔºúÔºùÔºûÔºüÔº†Ôº°Ôº¢Ôº£Ôº§Ôº•Ôº¶ÔºßÔº®Ôº©Ôº™Ôº´Ôº¨Ôº≠ÔºÆÔºØÔº∞Ôº±Ôº≤Ôº≥Ôº¥ÔºµÔº∂Ôº∑Ôº∏ÔºπÔº∫ÔºªÔººÔºΩÔºæÔºøÔΩÄ'\\\n",
    "            r'ÔΩÅÔΩÇÔΩÉÔΩÑÔΩÖÔΩÜÔΩáÔΩàÔΩâÔΩäÔΩãÔΩåÔΩçÔΩéÔΩèÔΩêÔΩëÔΩíÔΩìÔΩîÔΩïÔΩñÔΩóÔΩòÔΩôÔΩöÔΩõÔΩúÔΩù]+')\n",
    "#================================\n",
    "def full_to_half(words):\n",
    "    temp = ''\n",
    "    if len(words) != 0:\n",
    "        for word in words:\n",
    "            temp += WIDTH_MAP[word]\n",
    "    return temp\n",
    "  \n",
    "def dataClearingPipe(row):\n",
    "    row = re.sub(URL_PATTERN, '', str(row)) # Clear URLs\n",
    "    row = re_URL_PATTERN2.sub('', str(row)) # Clear URLs\n",
    "    row = re.sub(re_HTML, '', str(row)) # Clear HTML tag\n",
    "    row = re.sub(re_Characters_All, ' ', str(row)) # Clear custom characters including spaces #1\n",
    "    row = re_ChiEng_Space.sub(r'\\1\\2', str(row)) # Clear Spaces between Chinese Words #1\n",
    "    row = re_ChiEng_Space2.sub(r'\\1\\2', str(row)) # Clear Spaces between Eng & Chinese Words\n",
    "    row = re_ChiEng_Space3.sub(r'\\1\\2', str(row)) # Clear Spaces between Chinese & Eng Words\n",
    "    row = re_ChiEng_Space.sub(r'\\1\\2', str(row)) # Clear Spaces between Chinese Words #2\n",
    "    row = re_Number_Space.sub(r'\\1\\2', str(row)) # Clear Spaces between Chinese & Numbers\n",
    "    row = re_Number_Space2.sub(r'\\1\\2', str(row)) # Clear Spaces between Numbers & Chinese\n",
    "    row = re_Number_Space3.sub(r'\\1\\2', str(row)) # Clear Spaces between Numbers & Numbers\n",
    "    row = row.lower() # Covert All CAPITAL letters to SMALL letters\n",
    "    # ==========FULL_WIDTH to HALF_WIDTH===============\n",
    "    if re_FullWidth.findall(row):\n",
    "        for word in re_FullWidth.findall(row):\n",
    "            half_word = full_to_half(word)\n",
    "            row = re.sub(word, half_word, row)\n",
    "    # =================================================\n",
    "    row = re.sub(re_Characters_All, ' ', str(row)) # Clear custom characters including spaces #2\n",
    "    return row.strip() #Return content with trimmed head&tail\n",
    "\n",
    "def dataCleaning(btn):  \n",
    "  clear_output()\n",
    "  for CSV in tqdm(list(CSV_PATH)[RANGE-1:], desc = f\"Progress\", ncols=100):\n",
    "  # for CSV in track(list(CSV_PATH)[RANGE-1:], description=f\"Conversion Progress\"):\n",
    "    # Initislization\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df['content'] = df['content'].swifter.apply(dataClearingPipe)\n",
    "    df = df[df['content'] != '']\n",
    "    df = df[df['content'] != 'None']\n",
    "    df.to_csv(destination, encoding=\"utf-8-sig\", index=False)\n",
    "  print(\"Done!\")\n",
    "\n",
    "def loadColumns(btn):\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def selectColumn(btn):\n",
    "  global column\n",
    "  column = columnsDropdown.value\n",
    "  print(f\"Split dataset according to {column}\")\n",
    "\n",
    "columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "  \n",
    "btn_load1 = button('Load Source!')\n",
    "btn_loadColumns = button('Load Columns!')\n",
    "btn_selectColumn = button('Select Column!')\n",
    "btn_setDest = button('Select Column!')\n",
    "btn_setRange = button('Set Range!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_loadColumns.on_click(loadColumns)\n",
    "btn_selectColumn.on_click(selectColumn)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(dataCleaning)\n",
    "\n",
    "input_boundedInt = boundedInt()\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "tab_selectSplitColumn = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Split dataset according to which column? :</font></b>\"),\n",
    "  btn_loadColumns,\n",
    "  columnsDropdown,\n",
    "  btn_selectColumn\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab.children = [tab_load1, tab_selectSplitColumn, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([tabTitles2[0],tabTitles2[2],tabTitles2[5], \"Set Range\", tabTitles2[-1]]):\n",
    "  tab.set_title(index, title)\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Processing Data (i.e. Text-mining process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1 Segment your text data (i.e \"content\") using Jieba! <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0.1 Segment text data using Jieba\n",
    "column = \"\"\n",
    "\n",
    "def loadColumns(btn):\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def selectColumn(btn):\n",
    "  global column\n",
    "  column = columnsDropdown.value\n",
    "  print(f\"Split dataset according to {column}\")\n",
    "\n",
    "def segmentDatasetContent(btn):\n",
    "  clear_output(wait=True)\n",
    "  for CSV in tqdm(list(CSV_PATH)[RANGE-1:], desc = f\"Conversion Progress\", ncols=100):\n",
    "    # for CSV in track(list(CSV_PATH)[RANGE-1:], description=f\"Conversion Progress\"):\n",
    "    # Initislization\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    npContent = np.array(df[column])\n",
    "    df[column] = [segmentation(x) for x in npContent]\n",
    "    df.to_csv(destination, encoding=\"utf-8-sig\", index=False)\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_loadColumns = button('Load Columns!')\n",
    "btn_selectColumn = button('Select Column!')\n",
    "btn_setDest = button('Set Path')\n",
    "btn_setRange = button('Set Range!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_loadColumns.on_click(loadColumns)\n",
    "btn_selectColumn.on_click(selectColumn)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(segmentDatasetContent)\n",
    "\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "\n",
    "tab_selectColumn = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Set column:</font></b>\"),\n",
    "  btn_loadColumns,\n",
    "  columnsDropdown,\n",
    "  btn_selectColumn\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "#Tab\n",
    "tab.children = [tab_load1, tab_selectColumn, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([tabTitles[0]] + [\"Select Column\"] + tabTitles[3:]):\n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.2 Replace your segmented data with Concept <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0.2 Replace your segmented data with Concept\n",
    "column = \"\"\n",
    "\n",
    "def replaceSegmentedDataset(btn):\n",
    "  clear_output(wait=True)\n",
    "  for CSV in tqdm(list(CSV_PATH)[RANGE-1:], desc = f\"Conversion Progress\", ncols= 100):\n",
    "  # Initialization\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    # df = mpd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    # npContent = np.array(df['content'])\n",
    "    # df['content'] = [segment_df_cfidf(x) for x in npContent]\n",
    "    df['content'] = df['content'].swifter.apply(segmented_replaceTerms_cfidf)\n",
    "    df.to_csv(destination, encoding=\"utf-8-sig\", index=False)\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_setDest = button('Set Path')\n",
    "btn_setRange = button('Set Range!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(replaceSegmentedDataset)\n",
    "\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Make sure your have segmented your dataset in Section 4.0.1</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your segmented dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "#Tab\n",
    "tab.children = [tab_load1, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([tabTitles[0]] + tabTitles[3:]):\n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.3 Load Your Segmented Dataset (done in section 4.0.1 & 4.0.2) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.0.2 load segmented dataset\n",
    "foldersOnly = list(filter(lambda x: path.isdir(x), listdir(DIR)))\n",
    "# Configure & Reload Widgets\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_load2 = button('Load Source!')\n",
    "\n",
    "btn_load1.on_click(loadDataset_clear)\n",
    "btn_load2.on_click(loadDataset_clear2)\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your 4.0.1 dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "tab_load2 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your 4.0.2 dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load2\n",
    "])\n",
    "\n",
    "tab.children = [tab_load1, tab_load2]\n",
    "tab.set_title(0, \"Load Sec 4.0.1 Data\")\n",
    "tab.set_title(1, \"Load Sec 4.0.2 Data\")\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1 Calculate TFIDF (by post_id or user) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.1 Calculate TFIDF\n",
    "client.restart() #Restart Dask\n",
    "RANGE = 1\n",
    "idf_groupby_column = \"\"\n",
    "target_groupby_column = \"\"\n",
    "columnsToIgnore = ['content']\n",
    "filtered_columns = \"\"\n",
    "\n",
    "def loadColumns_1(btn):\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_1.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def loadColumns_2(btn):\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_2.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def loadColumns_3(btn):\n",
    "  with open(CSV_PATH[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_3.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def selectColumn_idf(btn):\n",
    "  global idf_groupby_column\n",
    "  idf_groupby_column = columnsDropdown_1.value\n",
    "  print(f\"Calculate IDF according to {idf_groupby_column}\")\n",
    "\n",
    "def selectColumn_target(btn):\n",
    "  global target_groupby_column\n",
    "  target_groupby_column = columnsDropdown_2.value\n",
    "  print(f\"Set Target Column to {target_groupby_column}\")\n",
    "\n",
    "def addColumnsToIgnore(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore.append(columnsDropdown_3.value)\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def resetColumns(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore = ['content']\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def postTFIDF(btn):\n",
    "  clear_output(wait=True)\n",
    "  for CSV in tqdm(list(CSV_PATH)[RANGE-1:], desc = f\"Conversion Progress\", ncols=100):\n",
    "  # for CSV in track(list(CSV_PATH)[RANGE-1:], description=f\"Conversion Progress\"):\n",
    "    # Initislization\n",
    "    filtered_columns = columnsToIgnore.copy()\n",
    "    for x in ['content', idf_groupby_column, target_groupby_column]:\n",
    "      if x in filtered_columns:\n",
    "        filtered_columns.remove(x)\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df = df.drop(filtered_columns, axis=1)\n",
    "    df['content'] = df['content'].swifter.apply(segmented_df_tfidf)\n",
    "\n",
    "\n",
    "    try:\n",
    "      df_idf = df.swifter.groupby([idf_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))['content'] # Unable to use swifter  \n",
    "    except:\n",
    "      df_idf = df.groupby([idf_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))['content'] # Unable to use swifter  \n",
    "    #Groupby column for tfidf/cfidf\n",
    "    content_index = list(df.columns).index('content')\n",
    "    cols = [col for col in df.columns if col != 'content']\n",
    "\n",
    "    try:\n",
    "      df_target = df.swifter.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)\n",
    "    except:\n",
    "      df_target = df.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)\n",
    "    # content = df.swifter.groupby(['post_id'], as_index=False).agg({'content': \" \".join})['content']\n",
    "    try:\n",
    "      content = df.swifter.groupby([target_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])['content']\\\n",
    "              .reset_index(drop=True)\n",
    "    except:\n",
    "      content = df.groupby([target_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])['content']\\\n",
    "              .reset_index(drop=True)\n",
    "    try:         \n",
    "      df_target.insert(content_index, 'content', content)\n",
    "    except:\n",
    "      print(\"Insert column exception raised due to differnt logic of groupby, no need insert\")\n",
    "\n",
    "    channels = df_idf\n",
    "\n",
    "    posts = df_target['content']\n",
    "\n",
    "    for x in ['content', idf_groupby_column, target_groupby_column]:\n",
    "      if x in columnsToIgnore:\n",
    "        df_target = df_target.drop(x, axis=1)\n",
    "\n",
    "    #Word Count Vector\n",
    "    cv = CountVectorizer()\n",
    "    word_count_vector = cv.fit_transform(channels) #Generate word counts for idf\n",
    "\n",
    "    #Calculate idf using Word Count Vector\n",
    "    tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "    tfidf_transformer.fit(word_count_vector) # Calculate channel idf\n",
    "    count_vector = cv.transform(posts) #Generate word count matrix of docs\n",
    "    tfidf_score = tfidf_transformer.transform(count_vector)\n",
    "    temp = pd.DataFrame(tfidf_score.T.todense(), index=cv.get_feature_names_out(), columns=df_target[target_groupby_column]).T\n",
    "    tfidfList = []\n",
    "\n",
    "    for index in range(temp.shape[0]):\n",
    "      tfidfList.append(temp.iloc[index].sort_values(ascending=False)[:10].to_dict())\n",
    "    df_target.insert(len(df_target.columns), 'tfidf', tfidfList)\n",
    "    df_target.to_csv(destination, encoding='utf-8-sig', index=False)\n",
    "\n",
    "# =======================================================\n",
    "# =======================================================\n",
    "# =======================================================\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "# columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_loadColumns_1 = button('Load Columns!')\n",
    "btn_loadColumns_2 = button('Load Columns!')\n",
    "btn_loadColumns_3 = button('Load Columns!')\n",
    "btn_selectColumn_idf = button('Select Column!')\n",
    "btn_selectColumn_target = button('Select Column!')\n",
    "btn_addColumn_output = button('Add to drop list!')\n",
    "btn_resetColumn_output = button('Reset!')\n",
    "btn_setDest = button('Set Path')\n",
    "btn_setRange = button('Set Range!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_loadColumns_1.on_click(loadColumns_1)\n",
    "btn_loadColumns_2.on_click(loadColumns_2)\n",
    "btn_loadColumns_3.on_click(loadColumns_3)\n",
    "btn_selectColumn_idf.on_click(selectColumn_idf)\n",
    "btn_selectColumn_target.on_click(selectColumn_target)\n",
    "btn_addColumn_output.on_click(addColumnsToIgnore)\n",
    "btn_resetColumn_output.on_click(resetColumns)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(postTFIDF)\n",
    "\n",
    "input_boundedInt = boundedInt()\n",
    "\n",
    "tab_selectColumn_idf = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will group the data according to your selection</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>e.g selected 'channel', then then 'content' will be grouped by 'channel'</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select column to calculate IDF:</font></b>\"),\n",
    "  btn_loadColumns_1,\n",
    "  columnsDropdown_1,\n",
    "  btn_selectColumn_idf\n",
    "])\n",
    "\n",
    "tab_selectColumn_target = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section is to define your data level</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>e.g you want to get post-level tfidf, then select 'post_id' as target</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select target column:</font></b>\"),\n",
    "  btn_loadColumns_2,\n",
    "  columnsDropdown_2,\n",
    "  btn_selectColumn_target\n",
    "])\n",
    "\n",
    "tab_setOutputFormat = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will set the output format of your work</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>By default 'content' column will not be included in output file</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Drop unwanted columns: </font></b>\"),\n",
    "  btn_loadColumns_3,\n",
    "  columnsDropdown_3,\n",
    "  HBox([\n",
    "  btn_addColumn_output,\n",
    "  btn_resetColumn_output\n",
    "  ])\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "#Tab\n",
    "tab.children = [tab_selectColumn_idf, tab_selectColumn_target, tab_setOutputFormat, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([\"Set IDF Column\", \"Set Target Column\", \"Set Output Format\"] \\\n",
    "  + tabTitles[3:]):\n",
    "  \n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Calculate CFIDF (by post_id or user) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.2 Calculate CFIDF\n",
    "client.restart() #Restart Dask\n",
    "RANGE = 1\n",
    "idf_groupby_column = \"\"\n",
    "target_groupby_column = \"\"\n",
    "columnsToIgnore = ['content']\n",
    "filtered_columns = \"\"\n",
    "\n",
    "def loadColumns_1(btn):\n",
    "  with open(CSV_PATH2[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_1.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def loadColumns_2(btn):\n",
    "  with open(CSV_PATH2[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_2.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def loadColumns_3(btn):\n",
    "  with open(CSV_PATH2[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_3.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def selectColumn_idf(btn):\n",
    "  global idf_groupby_column\n",
    "  idf_groupby_column = columnsDropdown_1.value\n",
    "  print(f\"Calculate IDF according to {idf_groupby_column}\")\n",
    "\n",
    "def selectColumn_target(btn):\n",
    "  global target_groupby_column\n",
    "  target_groupby_column = columnsDropdown_2.value\n",
    "  print(f\"Set Target Column to {target_groupby_column}\")\n",
    "\n",
    "def addColumnsToIgnore(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore.append(columnsDropdown_3.value)\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def resetColumns(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore = ['content']\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def cfidfColumns(row):\n",
    "  columns = {}\n",
    "  # columns['post_id'] = row.name\n",
    "  # columns['cfidf_concept'] = row[conceptDict.keys()].sort_values(ascending=False).to_dict() # Old\n",
    "  cfidf_concept_values = [row[x] if x in row else 0 for x in conceptDict.keys()]\n",
    "  cfidf_concepts = {k:v for k,v in zip(conceptDict.keys(), cfidf_concept_values)}\n",
    "  # columns['cfidf_concept'] = {k:v for k,v in sorted(cfidf_concepts.items(), key=lambda item: item[1], reverse=True)}\n",
    "  # columns['cfidf'] = row.sort_values(ascending=False)[:10].to_dict()\n",
    "  # for key, value in conceptDict.items():\n",
    "  #   columns[key] = row[key]\n",
    "  columns.update(cfidf_concepts)\n",
    "  return pd.Series(columns)\n",
    "\n",
    "def postCFIDF(btn):\n",
    "  for CSV in tqdm(list(CSV_PATH2)[RANGE-1:], desc = f\"Conversion Progress\", ncols= 100):\n",
    "  # Initialization\n",
    "    filtered_columns = columnsToIgnore.copy()\n",
    "\n",
    "    for x in ['content', idf_groupby_column, target_groupby_column]:\n",
    "      if x in filtered_columns:\n",
    "        filtered_columns.remove(x)\n",
    "\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    # df = mpd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df = df.drop(filtered_columns, axis=1)\n",
    "    # npContent = np.array(df['content'])\n",
    "    # df['content'] = [segment_df_cfidf(x) for x in npContent]\n",
    "    df['content'] = df['content'].swifter.apply(join_segmented_df_cfidf)\n",
    "    #Groupby channel\n",
    "    # df_idf = df.groupby(['channel'], as_index=False).agg({'channel': 'first', 'content': ' '.join})\n",
    "    try:\n",
    "      df_idf = df.swifter.groupby([idf_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))['content']\n",
    "    except:\n",
    "      df_idf = df.groupby([idf_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))['content']\n",
    "    #Groupby column for tfidf/cfidf\n",
    "    content_index = list(df.columns).index('content')\n",
    "    cols = [col for col in df.columns if col != 'content']\n",
    "    \n",
    "    try:\n",
    "      df_target = df.swifter.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)\n",
    "    except:\n",
    "      df_target = df.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)\n",
    "      \n",
    "    try:\n",
    "      content = df.swifter.groupby([target_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])['content']\\\n",
    "              .reset_index(drop=True)\n",
    "    except:\n",
    "      content = df.groupby([target_groupby_column], as_index=False)['content']\\\n",
    "        .apply(lambda x: \" \".join(x))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])['content']\\\n",
    "              .reset_index(drop=True)\n",
    "    \n",
    "    try:\n",
    "      df_target.insert(content_index, 'content', content)\n",
    "    except:\n",
    "      print(\"Insert column exception raised due to differnt logic of groupby, no need insert\")\n",
    "    #tfidf (post-level by date)\n",
    "    # Here, maybe not necessary to copy df_idf & df_target['content'] again for the operation below\n",
    "    # channels = df_idf\n",
    "    posts = df_target['content']\n",
    "\n",
    "    for x in ['content', idf_groupby_column, target_groupby_column]:\n",
    "      if x in columnsToIgnore:\n",
    "        df_target = df_target.drop(x, axis=1)\n",
    "    #Word Count Vector\n",
    "    cv = CountVectorizer()\n",
    "    # df_idf == channels\n",
    "    word_count_vector = cv.fit_transform(df_idf) #Generate word counts for idf \n",
    "\n",
    "    #Calculate idf using Word Count Vector\n",
    "    tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "    tfidf_transformer.fit(word_count_vector) # Calculate channel idf\n",
    "    # df_target['content'] == posts\n",
    "    count_vector = cv.transform(posts) #Generate word count matrix of docs\n",
    "    tfidf_score = tfidf_transformer.transform(count_vector)\n",
    "    temp = pd.DataFrame(tfidf_score.T.todense(), index=cv.get_feature_names_out()\\\n",
    "      , columns=df_target[target_groupby_column]).T.reset_index(drop=True)\n",
    "    \n",
    "    df_output = pd.concat([df_target, temp.swifter.apply(cfidfColumns, axis=1)], axis=1)\n",
    "    # temp2.insert(1, \"channel\", df.channel)\n",
    "    df_output.to_csv(destination, encoding='utf-8-sig', index=False)\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "# columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_loadColumns_1 = button('Load Columns!')\n",
    "btn_loadColumns_2 = button('Load Columns!')\n",
    "btn_loadColumns_3 = button('Load Columns!')\n",
    "btn_selectColumn_idf = button('Select Column!')\n",
    "btn_selectColumn_target = button('Select Column!')\n",
    "btn_addColumn_output = button('Add to drop list!')\n",
    "btn_resetColumn_output = button('Reset!')\n",
    "btn_setDest = button('Set Path')\n",
    "btn_setRange = button('Set Range!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_loadColumns_1.on_click(loadColumns_1)\n",
    "btn_loadColumns_2.on_click(loadColumns_2)\n",
    "btn_loadColumns_3.on_click(loadColumns_3)\n",
    "btn_selectColumn_idf.on_click(selectColumn_idf)\n",
    "btn_selectColumn_target.on_click(selectColumn_target)\n",
    "btn_addColumn_output.on_click(addColumnsToIgnore)\n",
    "btn_resetColumn_output.on_click(resetColumns)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(postCFIDF)\n",
    "\n",
    "input_boundedInt = boundedInt()\n",
    "\n",
    "tab_selectColumn_idf = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will group the data according to your selection</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>e.g selected 'channel', then then 'content' will be grouped by 'channel'</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select column to calculate IDF:</font></b>\"),\n",
    "  btn_loadColumns_1,\n",
    "  columnsDropdown_1,\n",
    "  btn_selectColumn_idf\n",
    "])\n",
    "\n",
    "tab_selectColumn_target = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section is to define your data level</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>e.g you want to get post-level cfidf, then select 'post_id' as target</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select target column:</font></b>\"),\n",
    "  btn_loadColumns_2,\n",
    "  columnsDropdown_2,\n",
    "  btn_selectColumn_target\n",
    "])\n",
    "\n",
    "tab_setOutputFormat = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will set the output format of your work</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>By default 'content' column will not be included in output file</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Drop unwanted columns: </font></b>\"),\n",
    "  btn_loadColumns_3,\n",
    "  columnsDropdown_3,\n",
    "  HBox([\n",
    "  btn_addColumn_output,\n",
    "  btn_resetColumn_output\n",
    "  ])\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab.children = [tab_selectColumn_idf, tab_selectColumn_target, tab_setOutputFormat, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([\"Set IDF Column\", \"Set Target Column\", \"Set Output Format\"] \\\n",
    "  + tabTitles[3:]):\n",
    "  \n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Calculate Number of Concept Terms from extracted Terms (by post_id or user) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.3 Calculate number of concepts terms\n",
    "client.restart() #Restart Dask\n",
    "RANGE = 1\n",
    "target_groupby_column = \"\"\n",
    "columnsToIgnore = ['content']\n",
    "filtered_columns = \"\"\n",
    "\n",
    "def loadColumns_2(btn):\n",
    "  with open(CSV_PATH2[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_2.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def loadColumns_3(btn):\n",
    "  with open(CSV_PATH2[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_3.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def selectColumn_target(btn):\n",
    "  global target_groupby_column\n",
    "  target_groupby_column = columnsDropdown_2.value\n",
    "  print(f\"Set Target Column to {target_groupby_column}\")\n",
    "\n",
    "def addColumnsToIgnore(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore.append(columnsDropdown_3.value)\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def resetColumns(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore = ['content']\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def countTermsCFIDF(btn):\n",
    "  for CSV in tqdm(list(CSV_PATH2)[RANGE-1:], desc='Progress: ', ncols=100):\n",
    "\n",
    "    filtered_columns = columnsToIgnore.copy()\n",
    "    for x in ['content', target_groupby_column]:\n",
    "      if x in filtered_columns:\n",
    "        filtered_columns.remove(x)\n",
    "\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    # Counting Terms\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df = df.drop(filtered_columns, axis=1)\n",
    "\n",
    "    df['content'] = df['content'].swifter.apply(segmented_replaceTerms_cfidf)\n",
    "\n",
    "    content_index = list(df.columns).index('content')\n",
    "    cols = [col for col in df.columns if col != 'content']\n",
    "\n",
    "    try:\n",
    "      df_target = df.swifter.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)\n",
    "    except:\n",
    "      df_target = df.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "          .reset_index(drop=True)\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)\n",
    " \n",
    "    content = df.groupby([target_groupby_column], as_index=False)\\\n",
    "      .agg({'content': sum})['content']\n",
    "\n",
    "    try:\n",
    "      df_target.insert(content_index, 'content', content)\n",
    "    except:\n",
    "      print(\"Insert column exception raised due to differnt logic of groupby, no need insert\")\n",
    "    # df = df.groupby('post_id', as_index=False).agg({'post_id': 'first', 'channel': 'first', 'content': sum})\n",
    "    df_termsCounting = df_target['content']\\\n",
    "      .swifter.apply(countTerms)\\\n",
    "        .swifter.apply(cfidfTermsCounting)\n",
    "        \n",
    "    for x in ['content', target_groupby_column]:\n",
    "      if x in columnsToIgnore:\n",
    "        df_target = df_target.drop(x, axis=1)\n",
    "\n",
    "    # Concat\n",
    "\n",
    "    df_output = pd.concat([df_target, df_termsCounting], axis=1)\n",
    "    df_output.to_csv(destination, encoding='utf-8-sig', index=False)\n",
    "\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "# columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_loadColumns_2 = button('Load Columns!')\n",
    "btn_loadColumns_3 = button('Load Columns!')\n",
    "btn_selectColumn_target = button('Select Column!')\n",
    "btn_addColumn_output = button('Add Column!')\n",
    "btn_resetColumn_output = button('Reset!')\n",
    "btn_setRange = button('Set Range')\n",
    "btn_setDest = button('Set Path')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_loadColumns_2.on_click(loadColumns_2)\n",
    "btn_loadColumns_3.on_click(loadColumns_3)\n",
    "btn_selectColumn_target.on_click(selectColumn_target)\n",
    "btn_addColumn_output.on_click(addColumnsToIgnore)\n",
    "btn_resetColumn_output.on_click(resetColumns)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(countTermsCFIDF)\n",
    "\n",
    "input_boundedInt = boundedInt()\n",
    "\n",
    "\n",
    "tab_selectColumn_target = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section is to define your data level</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>e.g you want to calculate post-level number of concept terms, then select 'post_id' as target</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select target column:</font></b>\"),\n",
    "  btn_loadColumns_2,\n",
    "  columnsDropdown_2,\n",
    "  btn_selectColumn_target\n",
    "])\n",
    "\n",
    "tab_setOutputFormat = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will set the output format of your work</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>By default 'content' column will not be included in output file</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Drop unwanted columns: </font></b>\"),\n",
    "  btn_loadColumns_3,\n",
    "  columnsDropdown_3,\n",
    "  HBox([\n",
    "  btn_addColumn_output,\n",
    "  btn_resetColumn_output\n",
    "  ])\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "#Tab\n",
    "tab.children = [tab_selectColumn_target, tab_setOutputFormat, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([\"Set Target Column\", \"Set Output Format\"] \\\n",
    "  + tabTitles[3:]):\n",
    "  \n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Calculate Number of Comments contain Concepts (by post_id or user) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Calculate number of comments contain concepts\n",
    "client.restart() #Restart Dask\n",
    "RANGE = 1\n",
    "target_groupby_column = \"\"\n",
    "columnsToIgnore = ['content']\n",
    "filtered_columns = \"\"\n",
    "\n",
    "def loadColumns_2(btn):\n",
    "  with open(CSV_PATH2[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_2.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def loadColumns_3(btn):\n",
    "  with open(CSV_PATH2[0], 'r', encoding='utf-8-sig') as file:\n",
    "    columns = [column.strip('\\n') for column in file.readline().split(',')]\n",
    "    columnsDropdown_3.options = columns\n",
    "    print(f\"Successfully loaded the columns\")\n",
    "\n",
    "def selectColumn_target(btn):\n",
    "  global target_groupby_column\n",
    "  target_groupby_column = columnsDropdown_2.value\n",
    "  print(f\"Set Target Column to {target_groupby_column}\")\n",
    "\n",
    "def addColumnsToIgnore(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore.append(columnsDropdown_3.value)\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def resetColumns(btn):\n",
    "  global columnsToIgnore\n",
    "  columnsToIgnore = ['content']\n",
    "  print(f\"Columns to be Ignored: {columnsToIgnore}\")\n",
    "\n",
    "def countCommentsCFIDF(btn):\n",
    "  # global df_columns, df_commentsCounting\n",
    "  for CSV in tqdm(list(CSV_PATH2)[RANGE-1:], desc='Coversion Progress', ncols=100):\n",
    "    \n",
    "    filtered_columns = columnsToIgnore.copy()\n",
    "    for x in ['content', target_groupby_column]:\n",
    "      if x in filtered_columns:\n",
    "        filtered_columns.remove(x)\n",
    "\n",
    "    dest_filename = path.basename(CSV).split('.')[0] + '.csv'\n",
    "    destination = path.join(DEST_PATH, dest_filename)\n",
    "    # Counting Terms\n",
    "    df = pd.read_csv(CSV, encoding='utf-8-sig')\n",
    "    df = df.drop(filtered_columns, axis=1)\n",
    "    # npContent = np.array(df['content'])\n",
    "    # df['content'] = [segmentation_cfidf(x) for x in npContent] # Segment terms & Replace Concepts\n",
    "    df['content'] = df['content'].swifter.apply(segmented_replaceTerms_cfidf)\n",
    "    cfidf_comments_columns = df['content'].swifter.apply(cfidfCommentsCounting)\n",
    "    df = pd.concat([df, cfidf_comments_columns], axis=1)\n",
    "\n",
    "    cols = [col for col in df.columns if col not in cfidf_comments_columns.columns]\n",
    "    try:\n",
    "      df_target = df.swifter.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)[cols]\n",
    "    except:\n",
    "      df_target = df.groupby([target_groupby_column], as_index=False)[cols]\\\n",
    "        .apply(lambda x: x.head(1))\\\n",
    "            .sort_values(by=[target_groupby_column])\\\n",
    "              .reset_index(drop=True)[cols]\n",
    "\n",
    "    try:\n",
    "      df_columns = df.swifter.groupby([target_groupby_column], as_index=False)[cfidf_comments_columns.columns]\\\n",
    "        .apply(lambda x: x.sum())\\\n",
    "          .sort_values(by=[target_groupby_column])\\\n",
    "            .reset_index(drop=True)[cfidf_comments_columns.columns]\n",
    "    except:\n",
    "      df_columns = df.groupby([target_groupby_column], as_index=False)[cfidf_comments_columns.columns]\\\n",
    "        .apply(lambda x: x.sum())\\\n",
    "          .sort_values(by=[target_groupby_column])\\\n",
    "            .reset_index(drop=True)[cfidf_comments_columns.columns]\n",
    "    \n",
    "    cols = [col for col in df.columns if col != 'content']\n",
    "    for x in ['content', target_groupby_column]:\n",
    "      if x in columnsToIgnore:\n",
    "        df_target = df_target.drop(x, axis=1)\n",
    "\n",
    "    df_output = pd.concat([df_target, df_columns], axis=1)\n",
    "    df_output.to_csv(destination, encoding='utf-8-sig', index=False)\n",
    "    # df = pd.concat([df['post_id'], df_columns], axis=1)\n",
    "    # df_commentsCounting = df.groupby(['post_id'], as_index=False).sum()\n",
    "    # df_commentsCounting = df_commentsCounting.drop(['post_id'], axis=1)\n",
    "    # Read tfidf content\n",
    "    # content_index = list(df.columns).index('content')\n",
    "    # cols = [col for col in df.columns if col != 'content']\n",
    "\n",
    "    # df_cfidf = pd.read_csv(CFIDF_CSV, encoding='utf-8-sig')\n",
    "    # # Concat\n",
    "    # df_concat = pd.concat([df_cfidf, df_commentsCounting], axis=1)\n",
    "    # df_concat.to_csv(destination, encoding='utf-8-sig', index=False)\n",
    "\n",
    "foldersOnly = list(filter(lambda x: path.isdir(x), listdir(DIR)))\n",
    "#Widgets\n",
    "# columnsDropdown = Dropdown([], 'Select Column: ')\n",
    "\n",
    "btn_loadColumns_2 = button('Load Columns!')\n",
    "btn_loadColumns_3 = button('Load Columns!')\n",
    "btn_selectColumn_target = button('Select Column!')\n",
    "btn_addColumn_output = button('Add Column!')\n",
    "btn_resetColumn_output = button('Reset!')\n",
    "btn_setDest = button('Set Path')\n",
    "btn_setRange = button('Set Range')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_loadColumns_2.on_click(loadColumns_2)\n",
    "btn_loadColumns_3.on_click(loadColumns_3)\n",
    "btn_selectColumn_target.on_click(selectColumn_target)\n",
    "btn_addColumn_output.on_click(addColumnsToIgnore)\n",
    "btn_resetColumn_output.on_click(resetColumns)\n",
    "btn_setRange.on_click(setRange)\n",
    "btn_setDest.on_click(setDestination)\n",
    "btn_exeFx.on_click(countCommentsCFIDF)\n",
    "\n",
    "input_boundedInt = boundedInt()\n",
    "\n",
    "tab_selectColumn_target = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section is to define your data level</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>e.g you want to calculate post-level number of concept comments, then select 'post_id' as target</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select target column:</font></b>\"),\n",
    "  btn_loadColumns_2,\n",
    "  columnsDropdown_2,\n",
    "  btn_selectColumn_target\n",
    "])\n",
    "\n",
    "tab_setOutputFormat = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>This section will set the output format of your work</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>By default 'content' column will not be included in output file</font></b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Drop unwanted columns: </font></b>\"),\n",
    "  btn_loadColumns_3,\n",
    "  columnsDropdown_3,\n",
    "  HBox([\n",
    "  btn_addColumn_output,\n",
    "  btn_resetColumn_output\n",
    "  ])\n",
    "])\n",
    "\n",
    "tab_setDest = VBox([\n",
    "  widgets.HTML(value=\"Select Output Destination: <b><font style='color:red'>Make sure you have created a folder first!</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_setDest\n",
    "  ])\n",
    "\n",
    "tab_setRange = VBox([\n",
    "  widgets.HTML(value=\"Set the Starting Position for processing: <b>Default processing the <font style='color:red'>FIRST</font> file</b>\"),\n",
    "  input_boundedInt,\n",
    "  btn_setRange\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "#Tab\n",
    "tab.children = [tab_selectColumn_target, tab_setOutputFormat, tab_setDest, tab_setRange, tab_execute]\n",
    "for index, title in enumerate([\"Set Target Column\", \"Set Output Format\"] \\\n",
    "  + tabTitles[3:]):\n",
    "  \n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Post-processing <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Merge splitted CSVs into single CSV! (optional) (e.g merge 183 days) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.1 merge splitted CSVs\n",
    "fileName = None\n",
    "# Set File Name & Path\n",
    "def setFileName(btn):\n",
    "  global fileName\n",
    "  fileName = path.join(folder_pathDisplay1.value, input_Text.value + \".csv\")\n",
    "  print(f\"Successfully set file name to {input_Text.value}\")\n",
    "\n",
    "def mergeToSingleCSV(btn):\n",
    "  print('Processing')\n",
    "  with open(fileName, 'w', encoding='utf-8-sig') as file:\n",
    "    for p_index, CSV in tqdm(list(enumerate(CSV_PATH)), desc=\"Progress: \", ncols=100):\n",
    "      with open(CSV, encoding=\"utf-8-sig\") as f:\n",
    "          for idx, line in enumerate(f):\n",
    "              if p_index == 0 and idx == 0:\n",
    "                file.write(line)\n",
    "              elif idx>0:\n",
    "                file.write(line)\n",
    "  print('Done')\n",
    "\n",
    "# Configure & Reload Widgets\n",
    "input_Text = inputText('File name:')\n",
    "\n",
    "btn_load1 = button('Load Source!')\n",
    "btn_setFileName = button('Set!')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_load1.on_click(loadDataset)\n",
    "btn_setFileName.on_click(setFileName)\n",
    "btn_exeFx.on_click(mergeToSingleCSV)\n",
    "\n",
    "tab_load1 = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select & Load your dataset Folder:</font></b>\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  btn_load1\n",
    "])\n",
    "\n",
    "tab_setFileName = VBox([\n",
    "  widgets.HTML(value=\"<b>Default output to asset folder!!</b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Set output filename:</font></b>\"),\n",
    "  input_Text,\n",
    "  btn_setFileName\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value='<b>If Everything is ready, Click the button below:</b>'),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab.children = [tab_load1, tab_setFileName, tab_execute]\n",
    "for index, title in enumerate([tabTitles2[0],tabTitles2[1], tabTitles2[-1]]):\n",
    "  tab.set_title(index, title)\n",
    "display(tab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Combine different Outputs into single CSV! (completed section 5.1 first!) (e.g combine post-level & user-level) <font color=\"#FF0000\">(Execute & Configure)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 combine different outputs\n",
    "RANGE = 1\n",
    "CSV_LIST = []\n",
    "columnsToDrop = []\n",
    "dropHeader = False\n",
    "fileName = None\n",
    "\n",
    "def addFilesToMerge(btn):\n",
    "  global CSV_LIST\n",
    "  filePath = path.join(folder_pathDisplay1.value, file_dropdown1.value)\n",
    "  CSV_LIST.append(filePath)\n",
    "  print(f\"Data to be Merged: {CSV_LIST}\")\n",
    "\n",
    "def resetFiles(btn):\n",
    "  global CSV_LIST\n",
    "  CSV_LIST.clear()\n",
    "  print(f\"Data to be Merged: {CSV_LIST}\")\n",
    "\n",
    "def setFileName(btn):\n",
    "  global fileName\n",
    "  fileName = path.join(folder_pathDisplay1.value, input_Text.value + \".csv\")\n",
    "  print(f\"Successfully set file name to {input_Text.value}\")\n",
    "  \n",
    "def loadColumns(btn):\n",
    "  columns = []\n",
    "  for csv in CSV_LIST:\n",
    "    df = pd.read_csv(csv, encoding=\"utf-8-sig\")\n",
    "    columns.extend(df.columns.values.tolist())\n",
    "  columnsDropdown.options = [*set(columns)]\n",
    "\n",
    "def addDropColumn(btn):\n",
    "  global columnsToDrop\n",
    "  columnsToDrop.append(columnsDropdown.value)\n",
    "  print(F\"Columns to be dropped: {columnsToDrop}\")\n",
    "\n",
    "def resetDropColumn(btn):\n",
    "  global columnsToDrop\n",
    "  columnsToDrop.clear()\n",
    "  print(\"Columns to be dropped has beend cleared!!\")\n",
    "\n",
    "def combineCSVs(btn):\n",
    "  print('Processing')\n",
    "  dfs = [pd.read_csv(csv, encoding='utf-8-sig') for csv in CSV_LIST]\n",
    "  df = pd.concat(dfs, axis=1)\n",
    "  df = df.loc[:,~df.T.duplicated(keep='first')]\n",
    "  print(headersDropdown.value)\n",
    "  if len(columnsToDrop) != 0: \n",
    "    df = df.drop(columnsToDrop, axis=1)\n",
    "  if headersDropdown.value == \"Yes\":\n",
    "    df.to_csv(fileName, encoding='utf-8-sig', index=False, header=False)\n",
    "  else:\n",
    "    df.to_csv(fileName, encoding='utf-8-sig', index=False, header=True)\n",
    "    # df = df.drop(index=df.index[0], axis=0, inplace=True)\n",
    "  print('Done')\n",
    "\n",
    "foldersOnly = list(filter(lambda x: path.isdir(x), listdir(DIR)))\n",
    "#Widgets\n",
    "input_Text = inputText('File name:')\n",
    "\n",
    "columnsDropdown = Dropdown([], 'Column: ')\n",
    "headersDropdown = Dropdown([\"Yes\", \"No\"], 'Option: ')\n",
    "headersDropdown.value = \"No\"\n",
    "\n",
    "btn_addFile_output = button('Add File!')\n",
    "btn_resetFile_output = button('Reset!')\n",
    "btn_loadColumns = button('Load Output Columns')\n",
    "btn_addDropColumns = button('Add Columns')\n",
    "btn_resetDropColumns = button('Reset Columns')\n",
    "btn_setFileName = button('Set!')\n",
    "# btn_setRange = button('Set Range')\n",
    "btn_exeFx = button('Execute!')\n",
    "\n",
    "btn_addFile_output.on_click(addFilesToMerge)\n",
    "btn_resetFile_output.on_click(resetFiles)\n",
    "btn_loadColumns.on_click(loadColumns)\n",
    "btn_addDropColumns.on_click(addDropColumn)\n",
    "btn_resetDropColumns.on_click(resetDropColumn)\n",
    "btn_setFileName.on_click(setFileName)\n",
    "# btn_setRange.on_click(setRange)\n",
    "btn_exeFx.on_click(combineCSVs)\n",
    "\n",
    "input_boundedInt = boundedInt()\n",
    "\n",
    "tab_addFileToMerge = VBox([\n",
    "  widgets.HTML(value=\"Add file that you want to merge in sequence:\"),\n",
    "  folder_dropdown1,\n",
    "  folder_pathDisplay1,\n",
    "  file_dropdown1,\n",
    "  HBox([\n",
    "  btn_addFile_output,\n",
    "  btn_resetFile_output,\n",
    "  ])\n",
    "])\n",
    "\n",
    "tab_setFileName = VBox([\n",
    "  widgets.HTML(value=\"<b>Default output to asset folder!!</b>\"),\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Set output filename:</font></b>\"),\n",
    "  input_Text,\n",
    "  btn_setFileName\n",
    "])\n",
    "\n",
    "tab_dropColumn = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Only load the columns when you need to drop the output columns!!</font></b>\"),\n",
    "  btn_loadColumns,\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Select the column that your want to drop!!</font></b>\"),\n",
    "  columnsDropdown,\n",
    "  HBox([\n",
    "  btn_addDropColumns,\n",
    "  btn_resetDropColumns\n",
    "  ])\n",
    "])\n",
    "\n",
    "tab_execute = VBox([\n",
    "  widgets.HTML(value=\"<b><font style='color:red'>Do you want to keep the header (Column Names)? Keep header by default.</font>:</b>\"),\n",
    "  headersDropdown,\n",
    "  widgets.HTML(value=\"<b>If Everything is ready, Click the button below:</b>\"),\n",
    "  btn_exeFx\n",
    "])\n",
    "\n",
    "tab.children = [tab_addFileToMerge, tab_setFileName, tab_dropColumn, tab_execute]\n",
    "for index, title in enumerate([\"Add Files\", tabTitles2[1], \"Drop Columns\"] + tabTitles2[7:]):\n",
    "  tab.set_title(index, title)\n",
    "\n",
    "display(tab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1ad887d376bf5852405374cd315b8ebf0e638ed1545cbf9d851b86502370a90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
